#!/usr/bin/env python3
# coding: utf-8

import requests
from bs4 import BeautifulSoup
from ics import Calendar, Event
from datetime import datetime, timedelta, date
import re
import json
import os
import time
import random
from urllib.parse import urljoin, quote, urlparse, parse_qs
import argparse
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('scraper.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ë–ï–ó –ö–ê–ö–ò–•-–õ–ò–ë–û –ª–∏–º–∏—Ç–æ–≤
MAX_RETRIES = 3              
BACKOFF_FACTOR = 3           
BASE_DELAY = 5               
RANDOM_DELAY = 3             
PAGE_DELAY = 8               
DETAIL_DELAY = 12            

# –°—Ç—Ä–∞–Ω—ã, —Ñ–∏–ª—å–º—ã –∫–æ—Ç–æ—Ä—ã—Ö –ù–ï –≤–∫–ª—é—á–∞—Ç—å –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä—å
EXCLUDE_COUNTRIES = ['–†–æ—Å—Å–∏—è']

# –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
parser = argparse.ArgumentParser(description='–ü–æ–ª–Ω–æ—Å—Ç—å—é –±–µ–∑–ª–∏–º–∏—Ç–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –∞—Ñ–∏—à–∏ —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º —Å–µ–∞–Ω—Å–æ–≤')
parser.add_argument(
    '--exclude-country',
    action='append',
    default=[],
    help='–°—Ç—Ä–∞–Ω–∞, –∫–æ—Ç–æ—Ä—É—é –Ω–µ –≤–∫–ª—é—á–∞—Ç—å –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä—å (–º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ)'
)
parser.add_argument(
    '--delay',
    type=int,
    default=5,
    help='–ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö'
)
parser.add_argument(
    '--skip-details',
    action='store_true',
    help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∏–ª—å–º–∞—Ö (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –±–µ–∑ —Å—Ç—Ä–∞–Ω)'
)
# –£–ë–†–ê–ù–´ –∞—Ä–≥—É–º–µ–Ω—Ç—ã --max-movies –∏ --max-pages

args = parser.parse_args()

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –µ—Å–ª–∏ –æ–Ω–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã
if args.exclude_country:
    EXCLUDE_COUNTRIES = args.exclude_country

if args.delay:
    BASE_DELAY = args.delay
SKIP_DETAILS = args.skip_details

def smart_delay(request_type='default'):
    """
    –£–º–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
    """
    delays = {
        'default': BASE_DELAY,
        'detail': DETAIL_DELAY,
        'page': PAGE_DELAY,
        'retry': BASE_DELAY * 2
    }

    base_delay = delays.get(request_type, BASE_DELAY)
    actual_delay = base_delay + random.uniform(1, RANDOM_DELAY)

    time.sleep(actual_delay)
    logger.debug(f"–ó–∞–¥–µ—Ä–∂–∫–∞ {request_type}: {actual_delay:.2f} —Å–µ–∫")

def get_soup(url, retries=MAX_RETRIES, request_type='default'):
    """
    –ü–æ–ª—É—á–∏—Ç—å –æ–±—ä–µ–∫—Ç BeautifulSoup –ø–æ URL —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π HTTP 429
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0'
    }

    session = requests.Session()
    session.headers.update(headers)

    delay = BASE_DELAY
    for attempt in range(1, retries + 1):
        try:
            logger.debug(f"–ó–∞–ø—Ä–æ—Å {attempt}/{retries} –¥–ª—è {url[:60]}...")

            if attempt > 1:
                smart_delay('retry')

            resp = session.get(url, timeout=45)

            if resp.status_code == 429:
                wait_time = delay * BACKOFF_FACTOR
                logger.warning(f"HTTP 429 –¥–ª—è {url[:60]}... –û–∂–∏–¥–∞–Ω–∏–µ {wait_time} —Å–µ–∫ (–ø–æ–ø—ã—Ç–∫–∞ {attempt})")
                time.sleep(wait_time)
                delay *= BACKOFF_FACTOR
                continue
            elif resp.status_code == 404:
                logger.warning(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {url[:60]}...")
                return None
            elif resp.status_code == 403:
                logger.warning(f"–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω (403): {url[:60]}...")
                time.sleep(delay * 2)
                delay *= 2
                continue

            resp.raise_for_status()
            logger.debug(f"–£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è {url[:60]}... (—Å—Ç–∞—Ç—É—Å: {resp.status_code})")

            smart_delay(request_type)

            return BeautifulSoup(resp.text, 'html.parser')

        except requests.exceptions.Timeout:
            logger.warning(f"–¢–∞–π–º–∞—É—Ç –¥–ª—è {url[:60]}... (–ø–æ–ø—ã—Ç–∫–∞ {attempt})")
            if attempt < retries:
                time.sleep(delay)
                delay *= BACKOFF_FACTOR
        except requests.exceptions.RequestException as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è {url[:60]}... (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {e}")
            if attempt < retries:
                time.sleep(delay)
                delay *= BACKOFF_FACTOR
            else:
                logger.error(f"–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–ª—è {url[:60]}...")
                return None

    return None

def parse_schedule_calendar(soup):
    """
    –ü–∞—Ä—Å–∏—Ç—å –∫–∞–ª–µ–Ω–¥–∞—Ä—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —Å–µ–∞–Ω—Å–æ–≤ –∏ –Ω–∞–π—Ç–∏ –±–ª–∏–∂–∞–π—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –¥–∞—Ç—É
    """
    available_dates = []

    # –ü–æ–∏—Å–∫ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –≤–∏–¥–∂–µ—Ç–∞
    calendar_selectors = [
        '.EyErB',  # –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –∫–∞–ª–µ–Ω–¥–∞—Ä—è –∏–∑ –ø—Ä–∏–º–µ—Ä–∞
        '[aria-label="–ö–∞–ª–µ–Ω–¥–∞—Ä—å"]',
        '.calendar',
        '.schedule-calendar'
    ]

    calendar_widget = None
    for selector in calendar_selectors:
        calendar_widget = soup.select_one(selector)
        if calendar_widget:
            logger.debug(f"–ù–∞–π–¥–µ–Ω –∫–∞–ª–µ–Ω–¥–∞—Ä—å —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
            break

    if not calendar_widget:
        logger.debug("–ö–∞–ª–µ–Ω–¥–∞—Ä—å —Å–µ–∞–Ω—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return None

    # –ü–æ–∏—Å–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –¥–∞—Ç (—Å—Å—ã–ª–∫–∏, –Ω–µ –∫–Ω–æ–ø–∫–∏ disabled)
    date_links = calendar_widget.find_all('a', class_='pdT6c')

    for link in date_links:
        try:
            aria_label = link.get('aria-label', '')
            day_elem = link.select_one('.YCVqY')
            if day_elem:
                day_number = day_elem.get_text(strip=True)

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Å—è—Ü –∏ –≥–æ–¥ –∏–∑ aria-label
                if '–æ–∫—Ç—è–±—Ä—è' in aria_label:
                    month = 10
                    year = 2025
                elif '–Ω–æ—è–±—Ä—è' in aria_label:
                    month = 11
                    year = 2025
                elif '–¥–µ–∫–∞–±—Ä—è' in aria_label:
                    month = 12
                    year = 2025
                else:
                    now = datetime.now()
                    month = now.month
                    year = now.year

                try:
                    show_date = date(year, month, int(day_number))
                    available_dates.append(show_date)
                    logger.debug(f"–ù–∞–π–¥–µ–Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–∞—è –¥–∞—Ç–∞: {show_date}")
                except ValueError as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã {day_number}.{month}.{year}: {e}")
                    continue

        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —ç–ª–µ–º–µ–Ω—Ç–∞ –¥–∞—Ç—ã: {e}")
            continue

    if available_dates:
        available_dates.sort()
        nearest_date = available_dates[0]
        logger.debug(f"–ë–ª–∏–∂–∞–π—à–∞—è –¥–æ—Å—Ç—É–ø–Ω–∞—è –¥–∞—Ç–∞: {nearest_date}")
        return nearest_date

    logger.debug("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä–µ")
    return None

def parse_showtimes_from_page(soup):
    """
    –ü–∞—Ä—Å–∏—Ç—å –≤—Ä–µ–º—è —Å–µ–∞–Ω—Å–æ–≤ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —Ñ–∏–ª—å–º–∞
    """
    showtimes = []

    time_selectors = [
        '.showtime',
        '.session-time', 
        '.time',
        '[data-time]',
        '.screening-time'
    ]

    for selector in time_selectors:
        time_elements = soup.select(selector)
        for elem in time_elements:
            time_text = elem.get_text(strip=True)
            time_match = re.search(r'(\d{1,2}[:.:]\d{2})', time_text)
            if time_match:
                time_str = time_match.group(1).replace('.', ':')
                try:
                    parsed_time = datetime.strptime(time_str, '%H:%M')
                    if time_str not in showtimes:
                        showtimes.append(time_str)
                except ValueError:
                    continue

    if not showtimes:
        page_text = soup.get_text()
        time_patterns = [
            r'(\d{1,2}:\d{2})',
            r'(\d{1,2}\.\d{2})',
            r'(\d{1,2}[:.:]\d{2})'
        ]

        for pattern in time_patterns:
            matches = re.findall(pattern, page_text)
            for match in matches:
                time_str = match.replace('.', ':')
                try:
                    parsed_time = datetime.strptime(time_str, '%H:%M')
                    hour = parsed_time.hour
                    if 6 <= hour <= 23:
                        if time_str not in showtimes:
                            showtimes.append(time_str)
                except ValueError:
                    continue

    return showtimes

def extract_movie_data_from_schedule(soup):
    """
    –ò–∑–≤–ª–µ—á—å –í–°–ï –¥–∞–Ω–Ω—ã–µ –æ —Ñ–∏–ª—å–º–∞—Ö –∏–∑ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∫–∏–Ω–æ—Ç–µ–∞—Ç—Ä–æ–≤ - –ë–ï–ó –ö–ê–ö–ò–•-–õ–ò–ë–û –õ–ò–ú–ò–¢–û–í
    """
    movies_data = []

    movie_selectors = [
        '.movie-item',
        '.film-item', 
        '.schedule-item',
        '[data-movie]',
        '.movie',
        '.film',
        'article',
        '.content-item',
        '.list-item',
        '.cinema-movie',
        '.schedule-movie',
        '.event-item',
        '.item'
    ]

    movie_elements = []
    for selector in movie_selectors:
        elements = soup.select(selector)
        if elements:
            movie_elements = elements
            logger.debug(f"–ù–∞–π–¥–µ–Ω—ã —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector} ({len(elements)} —à—Ç.)")
            break

    if not movie_elements:
        # –ü–æ–∏—Å–∫ –ø–æ —Å—Å—ã–ª–∫–∞–º - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏
        links = soup.find_all('a', href=True)
        movie_links = [link for link in links if 'movie' in link['href'] or 'film' in link['href']]

        logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(movie_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ñ–∏–ª—å–º—ã - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π")

        # –£–ë–†–ê–ù–û –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ [:MAX_MOVIES] - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï
        for idx, link in enumerate(movie_links, 1):
            title = link.get_text(strip=True)
            if title and len(title) > 3:
                movie_data = {
                    'title': title,
                    'url': urljoin('https://www.afisha.ru', link['href']),
                    'times': [],
                    'countries': [],
                    'nearest_show_date': None
                }
                movies_data.append(movie_data)

        logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(movies_data)} —Ñ–∏–ª—å–º–æ–≤ —á–µ—Ä–µ–∑ —Å—Å—ã–ª–∫–∏")
        return movies_data

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ - –í–°–ï –ë–ï–ó –ò–°–ö–õ–Æ–ß–ï–ù–ò–Ø
    logger.debug(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï {len(movie_elements)} –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ñ–∏–ª—å–º–æ–≤ –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π")

    # –£–ë–†–ê–ù–û –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ [:MAX_MOVIES] - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï —ç–ª–µ–º–µ–Ω—Ç—ã
    for idx, element in enumerate(movie_elements, 1):
        try:
            # –ü–æ–∏—Å–∫ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∏–ª—å–º–∞
            title_selectors = ['h1', 'h2', 'h3', '.title', '.name', 'a', 'strong']
            title = None

            for sel in title_selectors:
                title_elem = element.select_one(sel)
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    if title and len(title) > 3:
                        break

            if not title:
                continue

            # –ü–æ–∏—Å–∫ –≤—Ä–µ–º–µ–Ω–∏ —Å–µ–∞–Ω—Å–æ–≤ –≤ —ç–ª–µ–º–µ–Ω—Ç–µ
            times = []
            time_patterns = [
                r'(\d{1,2}[:.:]\d{2})',
                r'(\d{1,2}:\d{2})',
                r'(\d{1,2}\.\d{2})'
            ]

            element_text = element.get_text()
            for pattern in time_patterns:
                matches = re.findall(pattern, element_text)
                for match in matches:
                    try:
                        time_str = match.replace('.', ':')
                        parsed_time = datetime.strptime(time_str, '%H:%M')
                        if time_str not in times:
                            times.append(time_str)
                    except ValueError:
                        continue

            # –ü–æ–∏—Å–∫ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ñ–∏–ª—å–º
            movie_url = None
            link_elem = element.find('a', href=True)
            if link_elem:
                movie_url = urljoin('https://www.afisha.ru', link_elem['href'])

            movie_data = {
                'title': title,
                'url': movie_url,
                'times': times,
                'countries': [],
                'nearest_show_date': None
            }

            movies_data.append(movie_data)
            logger.debug(f"–î–æ–±–∞–≤–ª–µ–Ω —Ñ–∏–ª—å–º {idx}: {title} ({len(times)} —Å–µ–∞–Ω—Å–æ–≤)")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —ç–ª–µ–º–µ–Ω—Ç–∞ —Ñ–∏–ª—å–º–∞ {idx}: {e}")
            continue

    logger.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(movies_data)} —Ñ–∏–ª—å–º–æ–≤ –∏–∑ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
    return movies_data

def parse_all_schedule_pages(base_url):
    """
    –ü–∞—Ä—Å–∏—Ç—å –í–°–ï –°–£–©–ï–°–¢–í–£–Æ–©–ò–ï —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –ë–ï–ó –ö–ê–ö–ò–•-–õ–ò–ë–û –õ–ò–ú–ò–¢–û–í
    –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –¢–û–õ–¨–ö–û –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    """
    all_movies_data = []
    current_page = 1

    logger.info(f"üî• –ê–ë–°–û–õ–Æ–¢–ù–û –ë–ï–ó–õ–ò–ú–ò–¢–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ –í–°–ï–• —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è")
    logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¢–û–õ–¨–ö–û –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (404)")

    # –£–ë–†–ê–ù –ª–∏–º–∏—Ç MAX_PAGES - –ø–∞—Ä—Å–∏–º –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    while True:  # –ë–ï–°–ö–û–ù–ï–ß–ù–´–ô —Ü–∏–∫–ª - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ 404 –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        if current_page == 1:
            page_url = base_url
        else:
            page_url = f"{base_url}page{current_page}/"

        logger.info(f"üìÑ –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page}: {page_url}")

        soup = get_soup(page_url, request_type='page')

        if not soup:
            logger.info(f"‚ùå –°—Ç—Ä–∞–Ω–∏—Ü–∞ {current_page} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (404) - –ó–ê–í–ï–†–®–ê–ï–ú –ø–∞—Ä—Å–∏–Ω–≥")
            break

        page_movies = extract_movie_data_from_schedule(soup)

        if not page_movies:
            logger.info(f"‚ùå –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {current_page} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∏–ª—å–º–æ–≤ - –ó–ê–í–ï–†–®–ê–ï–ú –ø–∞—Ä—Å–∏–Ω–≥")
            break

        logger.info(f"‚úÖ –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {current_page} –Ω–∞–π–¥–µ–Ω–æ {len(page_movies)} —Ñ–∏–ª—å–º–æ–≤")

        # –î–æ–±–∞–≤–ª—è–µ–º –í–°–ï —Ñ–∏–ª—å–º—ã, –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Ç–æ–ª—å–∫–æ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
        new_movies_count = 0
        existing_titles = {movie['title'] for movie in all_movies_data}

        for movie in page_movies:
            if movie['title'] not in existing_titles:
                all_movies_data.append(movie)
                existing_titles.add(movie['title'])
                new_movies_count += 1

        logger.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ {new_movies_count} –Ω–æ–≤—ã—Ö —Ñ–∏–ª—å–º–æ–≤ (–≤—Å–µ–≥–æ: {len(all_movies_data)})")

        # –£–ë–†–ê–ù–ê –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ —Ñ–∏–ª—å–º–æ–≤ - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–æ –∫–æ–Ω—Ü–∞

        current_page += 1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        next_page_url = f"{base_url}page{current_page}/"
        logger.debug(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page}")

        smart_delay('page')

    logger.info(f"üé¨ –ò–¢–û–ì–û –Ω–∞–π–¥–µ–Ω–æ {len(all_movies_data)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤ –Ω–∞ {current_page - 1} —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö")
    return all_movies_data

def parse_movie_details_and_schedule(movie_url):
    """
    –ü–æ–ª—É—á–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Ñ–∏–ª—å–º–µ –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ —Å–µ–∞–Ω—Å–æ–≤
    """
    if not movie_url:
        return [], None, []

    logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: {movie_url[:60]}...")
    soup = get_soup(movie_url, request_type='detail')

    if not soup:
        return [], None, []

    # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω—ã
    countries = []
    country_selectors = [
        '[data-test="ITEM-META"] a',
        '.country',
        '.film-country',
        '.movie-country',
        'span:contains("–°—Ç—Ä–∞–Ω–∞")',
        '.meta-info',
        '.film-meta'
    ]

    for selector in country_selectors:
        country_elements = soup.select(selector)
        for el in country_elements:
            country_text = el.get_text(strip=True)
            if country_text and len(country_text) < 50 and country_text not in countries:
                if not any(word in country_text.lower() for word in ['–∂–∞–Ω—Ä', '—Ä–µ–∂–∏—Å—Å–µ—Ä', '–∞–∫—Ç–µ—Ä', '–≥–æ–¥', '–≤—Ä–µ–º—è']):
                    countries.append(country_text)

    # –ü–∞—Ä—Å–∏–º –±–ª–∏–∂–∞–π—à—É—é –¥–∞—Ç—É —Å–µ–∞–Ω—Å–æ–≤ –∏–∑ –∫–∞–ª–µ–Ω–¥–∞—Ä—è
    nearest_show_date = parse_schedule_calendar(soup)

    # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è —Å–µ–∞–Ω—Å–æ–≤
    showtimes = parse_showtimes_from_page(soup)

    return countries, nearest_show_date, showtimes

def create_calendar_event(movie_data):
    """
    –°–æ–∑–¥–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è –¥–ª—è —Ñ–∏–ª—å–º–∞ —Å —É—á–µ—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
    """
    title = movie_data['title']
    times = movie_data['times']
    countries = movie_data['countries']
    movie_url = movie_data['url']
    nearest_show_date = movie_data.get('nearest_show_date')

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã
    if any(country in EXCLUDE_COUNTRIES for country in countries):
        logger.debug(f"–ü—Ä–æ–ø—É—Å–∫ —Ñ–∏–ª—å–º–∞ '{title}' - —Å—Ç—Ä–∞–Ω–∞ –≤ —Å–ø–∏—Å–∫–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–π: {countries}")
        return None

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–±—ã—Ç–∏—è
    if nearest_show_date:
        event_date = nearest_show_date
        logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–∞—Ç–∞ –∏–∑ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: {event_date}")
    else:
        event_date = datetime.now().date() + timedelta(days=1)
        logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–∞—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {event_date}")

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
    if times:
        try:
            time_str = times[0]
            show_time = datetime.strptime(time_str, '%H:%M').time()
            event_datetime = datetime.combine(event_date, show_time)
        except ValueError:
            event_datetime = datetime.combine(event_date, datetime.min.time().replace(hour=19))
    else:
        event_datetime = datetime.combine(event_date, datetime.min.time().replace(hour=19))

    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è
    event = Event()
    event.name = title
    event.begin = event_datetime
    event.end = event_datetime + timedelta(hours=2)

    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è
    description_parts = [f"–§–∏–ª—å–º: {title}"]
    if countries:
        description_parts.append(f"–°—Ç—Ä–∞–Ω–∞: {', '.join(countries[:3])}")
    if times:
        description_parts.append(f"–°–µ–∞–Ω—Å—ã: {', '.join(times[:5])}")
    if nearest_show_date:
        description_parts.append(f"–ë–ª–∏–∂–∞–π—à–∏–π –ø–æ–∫–∞–∑: {nearest_show_date.strftime('%d.%m.%Y')}")
    description_parts.append(f"–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è: {event_datetime.strftime('%d.%m.%Y %H:%M')}")
    if movie_url:
        description_parts.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫: {movie_url}")

    event.description = '\n'.join(description_parts)
    if movie_url:
        event.url = movie_url

    logger.info(f"–°–æ–∑–¥–∞–Ω–æ —Å–æ–±—ã—Ç–∏–µ –¥–ª—è —Ñ–∏–ª—å–º–∞: {title} –Ω–∞ {event_datetime.strftime('%d.%m.%Y %H:%M')}")
    return event

def main():
    """
    –ü–û–õ–ù–û–°–¢–¨–Æ –ë–ï–ó–õ–ò–ú–ò–¢–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è
    """
    logger.info("üî• –ê–ë–°–û–õ–Æ–¢–ù–û –ë–ï–ó–õ–ò–ú–ò–¢–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∫–∏–Ω–æ—Ç–µ–∞—Ç—Ä–æ–≤ –ü–µ—Ä–º–∏")
    logger.info("‚ùå –ù–ï–¢ –õ–ò–ú–ò–¢–û–í: –Ω–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, –Ω–∏ –Ω–∞ —Ñ–∏–ª—å–º—ã")
    logger.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¢–û–õ–¨–ö–û –ø—Ä–∏: 404 —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Ñ–∏–ª—å–º–æ–≤")
    logger.info(f"–ü—Ä–æ–ø—É—Å–∫ –¥–µ—Ç–∞–ª–µ–π: {'–î–ê (—Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)' if SKIP_DETAILS else '–ù–ï–¢ (–ø–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è + —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ)'}")
    logger.info(f"–ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: {BASE_DELAY} —Å–µ–∫")
    logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã: {EXCLUDE_COUNTRIES}")

    base_schedule_url = 'https://www.afisha.ru/prm/schedule_cinema/'

    try:
        # –ü–∞—Ä—Å–∏–º –ê–ë–°–û–õ–Æ–¢–ù–û –í–°–ï —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
        all_movies_data = parse_all_schedule_pages(base_schedule_url)

        if not all_movies_data:
            logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∏–ª—å–º–æ–≤ –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
            cal = Calendar()
            test_event = Event()
            test_event.name = "–§–∏–ª—å–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            test_event.begin = datetime.now() + timedelta(days=1)
            test_event.end = test_event.begin + timedelta(hours=2)
            test_event.description = "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ñ–∏–ª—å–º—ã –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏ –∫–∏–Ω–æ—Ç–µ–∞—Ç—Ä–æ–≤"
            cal.events.add(test_event)
        else:
            cal = Calendar()
            successful_events = 0

            total_movies = len(all_movies_data)
            logger.info(f"üéØ –ù–∞—á–∏–Ω–∞–µ–º –ü–û–õ–ù–û–°–¢–¨–Æ –ë–ï–ó–õ–ò–ú–ò–¢–ù–£–Æ –æ–±—Ä–∞–±–æ—Ç–∫—É –í–°–ï–• {total_movies} –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤")

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ê–ë–°–û–õ–Æ–¢–ù–û –ö–ê–ñ–î–û–ì–û —Ñ–∏–ª—å–º–∞ –ë–ï–ó –ö–ê–ö–ò–•-–õ–ò–ë–û –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ô
            for idx, movie_data in enumerate(all_movies_data, 1):
                try:
                    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {idx}/{total_movies}: {movie_data['title']}")

                    # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
                    if not SKIP_DETAILS and movie_data['url']:
                        logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –¥–ª—è —Ñ–∏–ª—å–º–∞ {idx}")
                        countries, nearest_date, detailed_times = parse_movie_details_and_schedule(movie_data['url'])

                        movie_data['countries'] = countries
                        movie_data['nearest_show_date'] = nearest_date

                        # –î–æ–ø–æ–ª–Ω—è–µ–º –≤—Ä–µ–º—è —Å–µ–∞–Ω—Å–æ–≤
                        if detailed_times:
                            all_times = list(set(movie_data['times'] + detailed_times))
                            movie_data['times'] = sorted(all_times)
                    else:
                        if SKIP_DETAILS:
                            logger.debug(f"–ü—Ä–æ–ø—É—Å–∫ –¥–µ—Ç–∞–ª–µ–π –¥–ª—è —Ñ–∏–ª—å–º–∞ {idx} (—Ñ–ª–∞–≥ --skip-details)")
                        movie_data['countries'] = []
                        movie_data['nearest_show_date'] = None

                    # –°–æ–∑–¥–∞–µ–º —Å–æ–±—ã—Ç–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è
                    event = create_calendar_event(movie_data)

                    if event:
                        cal.events.add(event)
                        successful_events += 1

                    # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 50 —Ñ–∏–ª—å–º–æ–≤ (—É–≤–µ–ª–∏—á–µ–Ω –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤)
                    if idx % 50 == 0:
                        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx}/{total_movies} —Ñ–∏–ª—å–º–æ–≤, —Å–æ–∑–¥–∞–Ω–æ {successful_events} —Å–æ–±—ã—Ç–∏–π")

                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Ñ–∏–ª—å–º–∞–º–∏
                    if idx < total_movies:
                        smart_delay('default')

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∏–ª—å–º–∞ {movie_data['title']}: {e}")
                    continue

            logger.info(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_movies} —Ñ–∏–ª—å–º–æ–≤, —Å–æ–∑–¥–∞–Ω–æ {successful_events} —Å–æ–±—ã—Ç–∏–π")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        with open('calendar.ics', 'w', encoding='utf-8') as f:
            f.writelines(cal)

        logger.info(f"üìÖ –ö–∞–ª–µ–Ω–¥–∞—Ä—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω: calendar.ics ({len(cal.events)} —Å–æ–±—ã—Ç–∏–π)")
        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ: —Å–æ—Ö—Ä–∞–Ω—ë–Ω calendar.ics ({len(cal.events)} —Å–æ–±—ã—Ç–∏–π)")

        if os.path.exists('calendar.ics'):
            file_size = os.path.getsize('calendar.ics')
            logger.info(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")

    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        cal = Calendar()
        error_event = Event()
        error_event.name = "–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"
        error_event.begin = datetime.now() + timedelta(days=1)
        error_event.end = error_event.begin + timedelta(hours=2)
        error_event.description = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {str(e)}"
        cal.events.add(error_event)

        with open('calendar.ics', 'w', encoding='utf-8') as f:
            f.writelines(cal)

        raise

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        logger.info("–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise
