#!/usr/bin/env python3
# coding: utf-8

import requests
from bs4 import BeautifulSoup
from ics import Calendar, Event
from datetime import datetime, timedelta, date
import re
import json
import os
import time
import random
from urllib.parse import urljoin, quote, urlparse, parse_qs
import argparse
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('scraper.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ë–ï–ó –ª–∏–º–∏—Ç–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
MAX_RETRIES = 5              
BACKOFF_FACTOR = 5           
BASE_DELAY = 5               
RANDOM_DELAY = 3             
PAGE_DELAY = 8               
DETAIL_DELAY = 12            

# –°—Ç—Ä–∞–Ω—ã, —Ñ–∏–ª—å–º—ã –∫–æ—Ç–æ—Ä—ã—Ö –ù–ï –≤–∫–ª—é—á–∞—Ç—å –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä—å
EXCLUDE_COUNTRIES = ['–†–æ—Å—Å–∏—è']

# –ê—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ - –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–´ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
parser = argparse.ArgumentParser(description='–ë–µ–∑–ª–∏–º–∏—Ç–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –∞—Ñ–∏—à–∏ —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º —Å–µ–∞–Ω—Å–æ–≤')
parser.add_argument(
    '--exclude-country',
    action='append',
    default=[],
    help='–°—Ç—Ä–∞–Ω–∞, –∫–æ—Ç–æ—Ä—É—é –Ω–µ –≤–∫–ª—é—á–∞—Ç—å –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä—å (–º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ)'
)
parser.add_argument(
    '--max-movies',
    type=int,
    default=None,
    help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ñ–∏–ª—å–º–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é - –ë–ï–ó –õ–ò–ú–ò–¢–ê, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –í–°–ï)'
)
parser.add_argument(
    '--max-pages',
    type=int,
    default=None,
    help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é - –ë–ï–ó –õ–ò–ú–ò–¢–ê, –ø–∞—Ä—Å—è—Ç—Å—è –í–°–ï)'
)
parser.add_argument(
    '--delay',
    type=int,
    default=5,
    help='–ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö'
)
parser.add_argument(
    '--skip-details',
    action='store_true',
    help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∏–ª—å–º–∞—Ö (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –±–µ–∑ —Å—Ç—Ä–∞–Ω)'
)
args = parser.parse_args()

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã, –µ—Å–ª–∏ –æ–Ω–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã
if args.exclude_country:
    EXCLUDE_COUNTRIES = args.exclude_country

# –í–ê–ñ–ù–û: –õ–∏–º–∏—Ç—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —è–≤–Ω–æ –∑–∞–¥–∞–Ω—ã
MAX_MOVIES = args.max_movies  # None –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
MAX_PAGES = args.max_pages    # None –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

if args.delay:
    BASE_DELAY = args.delay
SKIP_DETAILS = args.skip_details

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫
if MAX_MOVIES:
    logger.info(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏–º–∏—Ç —Ñ–∏–ª—å–º–æ–≤: {MAX_MOVIES}")
else:
    logger.info("‚ùå –õ–∏–º–∏—Ç —Ñ–∏–ª—å–º–æ–≤ –û–¢–ö–õ–Æ–ß–ï–ù - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ")

if MAX_PAGES:
    logger.info(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü: {MAX_PAGES}")
else:
    logger.info("‚ùå –õ–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü –û–¢–ö–õ–Æ–ß–ï–ù - –ø–∞—Ä—Å—è—Ç—Å—è –í–°–ï —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ")

def smart_delay(request_type='default'):
    """
    –£–º–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
    """
    delays = {
        'default': BASE_DELAY,
        'detail': DETAIL_DELAY,
        'page': PAGE_DELAY,
        'retry': BASE_DELAY * 2
    }

    base_delay = delays.get(request_type, BASE_DELAY)
    actual_delay = base_delay + random.uniform(1, RANDOM_DELAY)

    time.sleep(actual_delay)
    logger.debug(f"–ó–∞–¥–µ—Ä–∂–∫–∞ {request_type}: {actual_delay:.2f} —Å–µ–∫")

def get_soup(url, retries=MAX_RETRIES, request_type='default'):
    """
    –ü–æ–ª—É—á–∏—Ç—å –æ–±—ä–µ–∫—Ç BeautifulSoup –ø–æ URL —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π HTTP 429
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0'
    }

    session = requests.Session()
    session.headers.update(headers)

    delay = BASE_DELAY
    for attempt in range(1, retries + 1):
        try:
            logger.debug(f"–ó–∞–ø—Ä–æ—Å {attempt}/{retries} –¥–ª—è {url[:60]}...")

            if attempt > 1:
                smart_delay('retry')

            resp = session.get(url, timeout=45)

            if resp.status_code == 429:
                wait_time = delay * BACKOFF_FACTOR
                logger.warning(f"HTTP 429 –¥–ª—è {url[:60]}... –û–∂–∏–¥–∞–Ω–∏–µ {wait_time} —Å–µ–∫ (–ø–æ–ø—ã—Ç–∫–∞ {attempt})")
                time.sleep(wait_time)
                delay *= BACKOFF_FACTOR
                continue
            elif resp.status_code == 404:
                logger.warning(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {url[:60]}...")
                return None
            elif resp.status_code == 403:
                logger.warning(f"–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω (403): {url[:60]}...")
                time.sleep(delay * 2)
                delay *= 2
                continue

            resp.raise_for_status()
            logger.debug(f"–£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è {url[:60]}... (—Å—Ç–∞—Ç—É—Å: {resp.status_code})")

            smart_delay(request_type)

            return BeautifulSoup(resp.text, 'html.parser')

        except requests.exceptions.Timeout:
            logger.warning(f"–¢–∞–π–º–∞—É—Ç –¥–ª—è {url[:60]}... (–ø–æ–ø—ã—Ç–∫–∞ {attempt})")
            if attempt < retries:
                time.sleep(delay)
                delay *= BACKOFF_FACTOR
        except requests.exceptions.RequestException as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è {url[:60]}... (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {e}")
            if attempt < retries:
                time.sleep(delay)
                delay *= BACKOFF_FACTOR
            else:
                logger.error(f"–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–ª—è {url[:60]}...")
                return None

    return None

def parse_schedule_calendar(soup):
    """
    –ü–∞—Ä—Å–∏—Ç—å –∫–∞–ª–µ–Ω–¥–∞—Ä—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —Å–µ–∞–Ω—Å–æ–≤ –∏ –Ω–∞–π—Ç–∏ –±–ª–∏–∂–∞–π—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –¥–∞—Ç—É
    """
    available_dates = []

    # –ü–æ–∏—Å–∫ –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω–æ–≥–æ –≤–∏–¥–∂–µ—Ç–∞
    calendar_selectors = [
        '.EyErB',  # –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –∫–∞–ª–µ–Ω–¥–∞—Ä—è –∏–∑ –ø—Ä–∏–º–µ—Ä–∞
        '[aria-label="–ö–∞–ª–µ–Ω–¥–∞—Ä—å"]',
        '.calendar',
        '.schedule-calendar'
    ]

    calendar_widget = None
    for selector in calendar_selectors:
        calendar_widget = soup.select_one(selector)
        if calendar_widget:
            logger.debug(f"–ù–∞–π–¥–µ–Ω –∫–∞–ª–µ–Ω–¥–∞—Ä—å —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
            break

    if not calendar_widget:
        logger.debug("–ö–∞–ª–µ–Ω–¥–∞—Ä—å —Å–µ–∞–Ω—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return None

    # –ü–æ–∏—Å–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –¥–∞—Ç (—Å—Å—ã–ª–∫–∏, –Ω–µ –∫–Ω–æ–ø–∫–∏ disabled)
    date_links = calendar_widget.find_all('a', class_='pdT6c')

    for link in date_links:
        try:
            aria_label = link.get('aria-label', '')
            day_elem = link.select_one('.YCVqY')
            if day_elem:
                day_number = day_elem.get_text(strip=True)

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Å—è—Ü –∏ –≥–æ–¥ –∏–∑ aria-label
                if '–æ–∫—Ç—è–±—Ä—è' in aria_label:
                    month = 10
                    year = 2025
                elif '–Ω–æ—è–±—Ä—è' in aria_label:
                    month = 11
                    year = 2025
                elif '–¥–µ–∫–∞–±—Ä—è' in aria_label:
                    month = 12
                    year = 2025
                else:
                    now = datetime.now()
                    month = now.month
                    year = now.year

                try:
                    show_date = date(year, month, int(day_number))
                    available_dates.append(show_date)
                    logger.debug(f"–ù–∞–π–¥–µ–Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–∞—è –¥–∞—Ç–∞: {show_date}")
                except ValueError as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã {day_number}.{month}.{year}: {e}")
                    continue

        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —ç–ª–µ–º–µ–Ω—Ç–∞ –¥–∞—Ç—ã: {e}")
            continue

    if available_dates:
        available_dates.sort()
        nearest_date = available_dates[0]
        logger.debug(f"–ë–ª–∏–∂–∞–π—à–∞—è –¥–æ—Å—Ç—É–ø–Ω–∞—è –¥–∞—Ç–∞: {nearest_date}")
        return nearest_date

    logger.debug("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞—Ç –≤ –∫–∞–ª–µ–Ω–¥–∞—Ä–µ")
    return None

def parse_showtimes_from_page(soup):
    """
    –ü–∞—Ä—Å–∏—Ç—å –≤—Ä–µ–º—è —Å–µ–∞–Ω—Å–æ–≤ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —Ñ–∏–ª—å–º–∞
    """
    showtimes = []

    time_selectors = [
        '.showtime',
        '.session-time', 
        '.time',
        '[data-time]',
        '.screening-time'
    ]

    for selector in time_selectors:
        time_elements = soup.select(selector)
        for elem in time_elements:
            time_text = elem.get_text(strip=True)
            time_match = re.search(r'(\d{1,2}[:.]\d{2})', time_text)
            if time_match:
                time_str = time_match.group(1).replace('.', ':')
                try:
                    parsed_time = datetime.strptime(time_str, '%H:%M')
                    if time_str not in showtimes:
                        showtimes.append(time_str)
                except ValueError:
                    continue

    if not showtimes:
        page_text = soup.get_text()
        time_patterns = [
            r'(\d{1,2}:\d{2})',
            r'(\d{1,2}\.\d{2})',
            r'(\d{1,2}[:.]\d{2})'
        ]

        for pattern in time_patterns:
            matches = re.findall(pattern, page_text)
            for match in matches:
                time_str = match.replace('.', ':')
                try:
                    parsed_time = datetime.strptime(time_str, '%H:%M')
                    hour = parsed_time.hour
                    if 6 <= hour <= 23:
                        if time_str not in showtimes:
                            showtimes.append(time_str)
                except ValueError:
                    continue

    return showtimes

def parse_movie_banner(soup):
    """
    –ù–∞–π—Ç–∏ –±–∞–Ω–Ω–µ—Ä/–ø–æ—Å—Ç–µ—Ä —Ñ–∏–ª—å–º–∞
    """
    banner_selectors = [
        'img[src*="mediastorage"]',  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è –±–∞–Ω–Ω–µ—Ä–æ–≤ afisha.ru
        '.poster img',
        '.movie-poster img',
        '.film-poster img',
        'img[alt*="–ø–æ—Å—Ç–µ—Ä"]',
        'img[alt*="poster"]',
        '.main-image img',
        '.hero-image img',
        'img[data-src*="mediastorage"]'
    ]

    for selector in banner_selectors:
        banner_elem = soup.select_one(selector)
        if banner_elem:
            # –ü–æ–ª—É—á–∞–µ–º src –∏–ª–∏ data-src
            banner_url = banner_elem.get('src') or banner_elem.get('data-src')
            if banner_url:
                # –î–µ–ª–∞–µ–º –ø–æ–ª–Ω—ã–π URL –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if banner_url.startswith('//'):
                    banner_url = 'https:' + banner_url
                elif banner_url.startswith('/'):
                    banner_url = 'https://www.afisha.ru' + banner_url

                logger.debug(f"–ù–∞–π–¥–µ–Ω –±–∞–Ω–Ω–µ—Ä: {banner_url}")
                return banner_url

    logger.debug("–ë–∞–Ω–Ω–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return None

def parse_movie_description(soup):
    """
    –ù–∞–π—Ç–∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞ –ø–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º "–û —Ñ–∏–ª—å–º–µ"
    """
    description_selectors = [
        # –ü–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞ "–û —Ñ–∏–ª—å–º–µ" –∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞ –Ω–∏–º —Ç–µ–∫—Å—Ç–∞
        'h2:contains("–û —Ñ–∏–ª—å–º–µ") + div',
        'h3:contains("–û —Ñ–∏–ª—å–º–µ") + div',
        'h2:contains("–û —Ñ–∏–ª—å–º–µ") + p',
        'h3:contains("–û —Ñ–∏–ª—å–º–µ") + p',
        '.about-movie',
        '.movie-description',
        '.film-description',
        '.description',
        '.synopsis',
        '.plot',
        '[data-test="ITEM-DESCRIPTION"]'
    ]

    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É "–û —Ñ–∏–ª—å–º–µ"
    about_headers = soup.find_all(['h1', 'h2', 'h3', 'h4'], string=re.compile(r'–û —Ñ–∏–ª—å–º–µ', re.I))
    for header in about_headers:
        # –ò—â–µ–º —Å–ª–µ–¥—É—é—â–∏–π —ç–ª–µ–º–µ–Ω—Ç —Å —Ç–µ–∫—Å—Ç–æ–º
        next_elem = header.find_next_sibling(['div', 'p', 'section'])
        if next_elem:
            description = next_elem.get_text(strip=True)
            if description and len(description) > 20:
                logger.debug(f"–ù–∞–π–¥–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –∑–∞–≥–æ–ª–æ–≤–æ–∫: {description[:100]}...")
                return description

    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
    for selector in description_selectors:
        if ':contains(' in selector:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä—ã —Å :contains, —Ç–∞–∫ –∫–∞–∫ BeautifulSoup –∏—Ö –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
            continue

        desc_elem = soup.select_one(selector)
        if desc_elem:
            description = desc_elem.get_text(strip=True)
            if description and len(description) > 20:
                logger.debug(f"–ù–∞–π–¥–µ–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä {selector}: {description[:100]}...")
                return description

    logger.debug("–û–ø–∏—Å–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    return None

def parse_age_rating(soup):
    """
    –ù–∞–π—Ç–∏ –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥ —Ñ–∏–ª—å–º–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 12+, 16+, 18+)
    """
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞
    age_patterns = [
        r'(\d+\+)',  # 12+, 16+, 18+
        r'(\d+ –ª–µ—Ç\+)',  # 12 –ª–µ—Ç+
        r'(–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)',
        r'(0\+)',
        r'(6\+)',
        r'(12\+)',
        r'(16\+)',
        r'(18\+)'
    ]

    # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–≥–æ —Ä–µ–π—Ç–∏–Ω–≥–∞
    age_selectors = [
        '.age-rating',
        '.rating',
        '.age',
        '[data-test="AGE-RATING"]',
        '.movie-rating',
        '.film-rating',
        '.restriction',
        '.mpaa'
    ]

    # –ü–æ–∏—Å–∫ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
    for selector in age_selectors:
        age_elem = soup.select_one(selector)
        if age_elem:
            age_text = age_elem.get_text(strip=True)
            for pattern in age_patterns:
                match = re.search(pattern, age_text, re.I)
                if match:
                    rating = match.group(1)
                    logger.debug(f"–ù–∞–π–¥–µ–Ω –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥ —á–µ—Ä–µ–∑ —Å–µ–ª–µ–∫—Ç–æ—Ä: {rating}")
                    return rating

    # –ü–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    page_text = soup.get_text()
    for pattern in age_patterns:
        matches = re.findall(pattern, page_text, re.I)
        for match in matches:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥
            if any(age in match for age in ['0+', '6+', '12+', '16+', '18+', '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π']):
                logger.debug(f"–ù–∞–π–¥–µ–Ω –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥ –≤ —Ç–µ–∫—Å—Ç–µ: {match}")
                return match

    logger.debug("–í–æ–∑—Ä–∞—Å—Ç–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω")
    return None

def extract_movie_data_from_schedule(soup):
    """
    –ò–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –æ —Ñ–∏–ª—å–º–∞—Ö –¢–û–õ–¨–ö–û –∏–∑ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ñ–∏–ª—å–º–æ–≤ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)
    """
    movies_data = []

    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–∞—Ä—Ç–æ—á–µ–∫ —Ñ–∏–ª—å–º–æ–≤ –Ω–∞ afisha.ru
    movie_card_selectors = [
        'div.oP17O[role="listitem"]',  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –∏–∑ –ø—Ä–∏–º–µ—Ä–∞
        'div[data-test="ITEM"]',      # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä –∏–∑ data-test
        '.oP17O',                     # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä –∫–ª–∞—Å—Å–∞
    ]

    movie_elements = []
    for selector in movie_card_selectors:
        elements = soup.select(selector)
        if elements:
            movie_elements = elements
            logger.debug(f"–ù–∞–π–¥–µ–Ω—ã —ç–ª–µ–º–µ–Ω—Ç—ã –∫–∞—Ä—Ç–æ—á–µ–∫ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector} ({len(elements)} —à—Ç.)")
            break

    if not movie_elements:
        logger.warning("‚ùå –ö–∞—Ä—Ç–æ—á–∫–∏ —Ñ–∏–ª—å–º–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã! –í–æ–∑–º–æ–∂–Ω–æ, –∏–∑–º–µ–Ω–∏–ª–∞—Å—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–∞–π—Ç–∞.")
        return movies_data

    logger.debug(f"üé¨ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(movie_elements)} –∫–∞—Ä—Ç–æ—á–µ–∫ —Ñ–∏–ª—å–º–æ–≤")

    for idx, card in enumerate(movie_elements, 1):
        try:
            # –ü–æ–∏—Å–∫ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∏–ª—å–º–∞
            title_selectors = [
                'a[data-test="LINK ITEM-NAME ITEM-URL"]',     # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –Ω–∞–∑–≤–∞–Ω–∏—è
                'a.CjnHd.y8A5E.nbCNS.yknrM',                 # –ü–æ–ª–Ω—ã–π –∫–ª–∞—Å—Å –∏–∑ –ø—Ä–∏–º–µ—Ä–∞
                'a[data-test*="ITEM-NAME"]',                  # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                '.QWR1k a',                                   # –°—Å—ã–ª–∫–∞ –≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–º –±–ª–æ–∫–µ
                'a[href*="/movie/"]'                          # –°—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ñ–∏–ª—å–º–∞
            ]

            title = None
            movie_url = None

            for sel in title_selectors:
                title_elem = card.select_one(sel)
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    # –ü–æ–ª—É—á–∞–µ–º URL —Ñ–∏–ª—å–º–∞
                    movie_url = title_elem.get('href')
                    if movie_url and not movie_url.startswith('http'):
                        movie_url = 'https://www.afisha.ru' + movie_url
                    break

            if not title or len(title) < 2:
                continue

            # –ü–æ–∏—Å–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–≥–æ–¥, –∂–∞–Ω—Ä)
            meta_info = []
            meta_selectors = [
                'div[data-test="ITEM-META"]',    # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                '.S_wwn',                        # –ö–ª–∞—Å—Å –∏–∑ –ø—Ä–∏–º–µ—Ä–∞
                '.QWR1k .S_wwn',                # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º
            ]

            for sel in meta_selectors:
                meta_elem = card.select_one(sel)
                if meta_elem:
                    meta_text = meta_elem.get_text(strip=True)
                    if meta_text:
                        meta_info.append(meta_text)
                    break

            # –ü–æ–∏—Å–∫ —Ä–µ–π—Ç–∏–Ω–≥–∞
            rating = None
            rating_selectors = [
                'div[data-test="RATING"]',       # –°–µ–ª–µ–∫—Ç–æ—Ä —Ä–µ–π—Ç–∏–Ω–≥–∞
                '.IrSqF.zPI3b.BNjPz.k96pX',     # –ö–ª–∞—Å—Å—ã —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏–∑ –ø—Ä–∏–º–µ—Ä–∞
            ]

            for sel in rating_selectors:
                rating_elem = card.select_one(sel)
                if rating_elem:
                    rating_text = rating_elem.get_text(strip=True)
                    try:
                        rating = float(rating_text)
                    except:
                        rating = rating_text
                    break

            # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/–ø–æ—Å—Ç–µ—Ä–∞
            image_url = None
            img_selectors = [
                'img[data-test="IMAGE ITEM-IMAGE"]',  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                'picture img',                        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ picture —ç–ª–µ–º–µ–Ω—Ç–µ
                'img[src*="mediastorage"]',           # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å mediastorage
            ]

            for sel in img_selectors:
                img_elem = card.select_one(sel)
                if img_elem:
                    image_url = img_elem.get('src')
                    if not image_url:
                        image_url = img_elem.get('data-src')
                    break

            # –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –æ —Ñ–∏–ª—å–º–µ
            movie_data = {
                'title': title,
                'url': movie_url,
                'times': [],                # –ó–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∑–∂–µ –ø—Ä–∏ –¥–µ—Ç–∞–ª—å–Ω–æ–º –ø–∞—Ä—Å–∏–Ω–≥–µ
                'countries': [],            # –ó–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∑–∂–µ –ø—Ä–∏ –¥–µ—Ç–∞–ª—å–Ω–æ–º –ø–∞—Ä—Å–∏–Ω–≥–µ
                'nearest_show_date': None,
                'banner_url': image_url,    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                'description': None,
                'age_rating': None,
                'meta_info': meta_info,     # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–≥–æ–¥, –∂–∞–Ω—Ä)
                'rating': rating            # –†–µ–π—Ç–∏–Ω–≥ —Ñ–∏–ª—å–º–∞
            }

            movies_data.append(movie_data)
            logger.debug(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Ñ–∏–ª—å–º {idx}: {title}")
            if meta_info:
                logger.debug(f"   üìã –ú–µ—Ç–∞: {', '.join(meta_info)}")
            if rating:
                logger.debug(f"   ‚≠ê –†–µ–π—Ç–∏–Ω–≥: {rating}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞—Ä—Ç–æ—á–∫–∏ {idx}: {e}")
            continue

    logger.debug(f"üé≠ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(movies_data)} —Ñ–∏–ª—å–º–æ–≤ –∏–∑ –∫–∞—Ä—Ç–æ—á–µ–∫")
    return movies_data

def parse_all_schedule_pages(base_url):
    """
    –ü–∞—Ä—Å–∏—Ç—å –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —Å —É—á–µ—Ç–æ–º –ª–∏–º–∏—Ç–æ–≤
    """
    all_movies_data = []
    current_page = 1

    if MAX_PAGES:
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å –ª–∏–º–∏—Ç–æ–º —Å—Ç—Ä–∞–Ω–∏—Ü: {MAX_PAGES}")
    else:
        logger.info(f"üî• –ë–ï–ó–õ–ò–ú–ò–¢–ù–´–ô –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü")

    # –¶–∏–∫–ª —Å —É—á–µ—Ç–æ–º –ª–∏–º–∏—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü
    while True:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü
        if MAX_PAGES and current_page > MAX_PAGES:
            logger.info(f"üõë –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü: {MAX_PAGES}")
            break

        if current_page == 1:
            page_url = base_url
        else:
            page_url = f"{base_url}page{current_page}/"

        logger.info(f"üìÑ –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {current_page}: {page_url}")

        soup = get_soup(page_url, request_type='page')

        if not soup:
            logger.info(f"‚ùå –°—Ç—Ä–∞–Ω–∏—Ü–∞ {current_page} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (404) - –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥")
            break

        page_movies = extract_movie_data_from_schedule(soup)

        if not page_movies:
            logger.info(f"‚ùå –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {current_page} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∏–ª—å–º–æ–≤ - –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥")
            break

        logger.info(f"‚úÖ –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {current_page} –Ω–∞–π–¥–µ–Ω–æ {len(page_movies)} —Ñ–∏–ª—å–º–æ–≤")

        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å–º—ã, –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        new_movies_count = 0
        existing_titles = {movie['title'] for movie in all_movies_data}

        for movie in page_movies:
            if movie['title'] not in existing_titles:
                all_movies_data.append(movie)
                existing_titles.add(movie['title'])
                new_movies_count += 1

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ —Ñ–∏–ª—å–º–æ–≤
                if MAX_MOVIES and len(all_movies_data) >= MAX_MOVIES:
                    logger.info(f"üõë –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Ñ–∏–ª—å–º–æ–≤: {MAX_MOVIES}")
                    all_movies_data = all_movies_data[:MAX_MOVIES]
                    return all_movies_data

        logger.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ {new_movies_count} –Ω–æ–≤—ã—Ö —Ñ–∏–ª—å–º–æ–≤ (–≤—Å–µ–≥–æ: {len(all_movies_data)})")

        current_page += 1
        smart_delay('page')

    logger.info(f"üé¨ –ò–¢–û–ì–û –Ω–∞–π–¥–µ–Ω–æ {len(all_movies_data)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤ –Ω–∞ {current_page - 1} —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö")
    return all_movies_data

def parse_movie_details_and_schedule(movie_url):
    """
    –ü–æ–ª—É—á–∏—Ç—å –†–ê–°–®–ò–†–ï–ù–ù–´–ï –¥–∞–Ω–Ω—ã–µ –æ —Ñ–∏–ª—å–º–µ: —Å—Ç—Ä–∞–Ω—ã, –±–∞–Ω–Ω–µ—Ä, –æ–ø–∏—Å–∞–Ω–∏–µ, –≤–æ–∑—Ä–∞—Å—Ç, —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
    """
    if not movie_url:
        return [], None, [], None, None, None

    logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π: {movie_url[:60]}...")
    soup = get_soup(movie_url, request_type='detail')

    if not soup:
        return [], None, [], None, None, None

    # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω—ã
    countries = []
    country_selectors = [
        '[data-test="ITEM-META"] a',
        '.country',
        '.film-country',
        '.movie-country',
        'span:contains("–°—Ç—Ä–∞–Ω–∞")',
        '.meta-info',
        '.film-meta'
    ]

    for selector in country_selectors:
        country_elements = soup.select(selector)
        for el in country_elements:
            country_text = el.get_text(strip=True)
            if country_text and len(country_text) < 50 and country_text not in countries:
                if not any(word in country_text.lower() for word in ['–∂–∞–Ω—Ä', '—Ä–µ–∂–∏—Å—Å–µ—Ä', '–∞–∫—Ç–µ—Ä', '–≥–æ–¥', '–≤—Ä–µ–º—è']):
                    countries.append(country_text)

    # –ü–∞—Ä—Å–∏–º –±–ª–∏–∂–∞–π—à—É—é –¥–∞—Ç—É —Å–µ–∞–Ω—Å–æ–≤ –∏–∑ –∫–∞–ª–µ–Ω–¥–∞—Ä—è
    nearest_show_date = parse_schedule_calendar(soup)

    # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è —Å–µ–∞–Ω—Å–æ–≤
    showtimes = parse_showtimes_from_page(soup)

    # –ü–∞—Ä—Å–∏–º –±–∞–Ω–Ω–µ—Ä —Ñ–∏–ª—å–º–∞
    banner_url = parse_movie_banner(soup)

    # –ü–∞—Ä—Å–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞
    description = parse_movie_description(soup)

    # –ü–∞—Ä—Å–∏–º –≤–æ–∑—Ä–∞—Å—Ç–Ω–æ–π —Ä–µ–π—Ç–∏–Ω–≥
    age_rating = parse_age_rating(soup)

    logger.debug(f"–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ë–∞–Ω–Ω–µ—Ä: {'‚úÖ' if banner_url else '‚ùå'}, –û–ø–∏—Å–∞–Ω–∏–µ: {'‚úÖ' if description else '‚ùå'}, –í–æ–∑—Ä–∞—Å—Ç: {'‚úÖ' if age_rating else '‚ùå'}")

    return countries, nearest_show_date, showtimes, banner_url, description, age_rating

def create_calendar_event(movie_data):
    """
    –°–æ–∑–¥–∞—Ç—å –ö–†–ê–°–ò–í–û–ï —Å–æ–±—ã—Ç–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è —Å —ç–º–æ–¥–∂–∏ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    """
    title = movie_data['title']
    times = movie_data['times']
    countries = movie_data['countries']
    movie_url = movie_data['url']
    nearest_show_date = movie_data.get('nearest_show_date')
    banner_url = movie_data.get('banner_url')
    description = movie_data.get('description')
    age_rating = movie_data.get('age_rating')
    meta_info = movie_data.get('meta_info', [])
    rating = movie_data.get('rating')

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã
    if any(country in EXCLUDE_COUNTRIES for country in countries):
        logger.debug(f"–ü—Ä–æ–ø—É—Å–∫ —Ñ–∏–ª—å–º–∞ '{title}' - —Å—Ç—Ä–∞–Ω–∞ –≤ —Å–ø–∏—Å–∫–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–π: {countries}")
        return None

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–±—ã—Ç–∏—è
    if nearest_show_date:
        event_date = nearest_show_date
        logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–∞—Ç–∞ –∏–∑ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: {event_date}")
    else:
        event_date = datetime.now().date() + timedelta(days=1)
        logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–∞—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {event_date}")

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
    if times:
        try:
            time_str = times[0]
            show_time = datetime.strptime(time_str, '%H:%M').time()
            event_datetime = datetime.combine(event_date, show_time)
        except ValueError:
            event_datetime = datetime.combine(event_date, datetime.min.time().replace(hour=19))
    else:
        event_datetime = datetime.combine(event_date, datetime.min.time().replace(hour=19))

    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è
    event = Event()
    # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∂–∏ —Ö–ª–æ–ø—É—à–∫–∏ –ø–µ—Ä–µ–¥ –Ω–∞–∑–≤–∞–Ω–∏–µ–º
    event.name = f"üé¨ {title}"
    event.begin = event_datetime
    event.end = event_datetime + timedelta(hours=2)

    # –°–æ–∑–¥–∞–Ω–∏–µ –ö–†–ê–°–ò–í–û–ì–û –æ–ø–∏—Å–∞–Ω–∏—è —Å —ç–º–æ–¥–∂–∏
    description_parts = []

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å —ç–º–æ–¥–∂–∏
    description_parts.append(f"üé¨ {title}")
    description_parts.append("=" * 50)

    # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    if rating:
        description_parts.append(f"‚≠ê –†–µ–π—Ç–∏–Ω–≥: {rating}")

    if age_rating:
        description_parts.append(f"üîû –í–æ–∑—Ä–∞—Å—Ç: {age_rating}")

    if meta_info:
        description_parts.append(f"üìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {', '.join(meta_info)}")

    if countries:
        country_emoji = "üåç"
        description_parts.append(f"{country_emoji} –°—Ç—Ä–∞–Ω–∞: {', '.join(countries[:3])}")

    # –û–ø–∏—Å–∞–Ω–∏–µ —Ñ–∏–ª—å–º–∞
    if description:
        description_parts.append("")
        description_parts.append("üìñ –û —Ñ–∏–ª—å–º–µ:")
        description_parts.append(description[:500] + ("..." if len(description) > 500 else ""))

    # –ë–∞–Ω–Ω–µ—Ä
    if banner_url:
        description_parts.append("")
        description_parts.append(f"üñºÔ∏è –ü–æ—Å—Ç–µ—Ä: {banner_url}")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ–∞–Ω—Å–∞—Ö
    description_parts.append("")
    description_parts.append("üé≠ –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ:")
    if times:
        description_parts.append(f"‚è∞ –°–µ–∞–Ω—Å—ã: {', '.join(times[:5])}")

    if nearest_show_date:
        description_parts.append(f"üìÖ –ë–ª–∏–∂–∞–π—à–∏–π –ø–æ–∫–∞–∑: {nearest_show_date.strftime('%d.%m.%Y')}")

    description_parts.append(f"üìÖ –î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è: {event_datetime.strftime('%d.%m.%Y %H:%M')}")

    # –ò—Å—Ç–æ—á–Ω–∏–∫
    if movie_url:
        description_parts.append("")
        description_parts.append(f"üîó –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏: {movie_url}")

    event.description = '\n'.join(description_parts)
    if movie_url:
        event.url = movie_url

    logger.info(f"–°–æ–∑–¥–∞–Ω–æ –∫—Ä–∞—Å–∏–≤–æ–µ —Å–æ–±—ã—Ç–∏–µ: üé¨ {title} –Ω–∞ {event_datetime.strftime('%d.%m.%Y %H:%M')}")
    return event

def main():
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ª–∏–º–∏—Ç–æ–≤ –∏ –†–ê–°–®–ò–†–ï–ù–ù–û–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
    """
    logger.info("üé¨ –ü–∞—Ä—Å–∏–Ω–≥ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∫–∏–Ω–æ—Ç–µ–∞—Ç—Ä–æ–≤ –ü–µ—Ä–º–∏ —Å –†–ê–°–®–ò–†–ï–ù–ù–û–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–∏–ª—å–º–∞—Ö")
    logger.info("üîß –ò–°–ü–†–ê–í–õ–ï–ù–ê –õ–û–ì–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê - —Ç–µ–ø–µ—Ä—å —Å–æ–±–∏—Ä–∞—é—Ç—Å—è –¢–û–õ–¨–ö–û —Ñ–∏–ª—å–º—ã –∏–∑ –∫–∞—Ä—Ç–æ—á–µ–∫!")

    if MAX_MOVIES:
        logger.info(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏–º–∏—Ç —Ñ–∏–ª—å–º–æ–≤: {MAX_MOVIES}")
    else:
        logger.info("‚ùå –õ–∏–º–∏—Ç —Ñ–∏–ª—å–º–æ–≤ –û–¢–ö–õ–Æ–ß–ï–ù - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –í–°–ï –Ω–∞–π–¥–µ–Ω–Ω—ã–µ")

    if MAX_PAGES:
        logger.info(f"–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü: {MAX_PAGES}")
    else:
        logger.info("‚ùå –õ–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü –û–¢–ö–õ–Æ–ß–ï–ù - –ø–∞—Ä—Å—è—Ç—Å—è –í–°–ï —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ")

    logger.info(f"–ü—Ä–æ–ø—É—Å–∫ –¥–µ—Ç–∞–ª–µ–π: {'–î–ê (—Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)' if SKIP_DETAILS else '–ù–ï–¢ (–ü–û–õ–ù–ê–Ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: —Å—Ç—Ä–∞–Ω—ã, –±–∞–Ω–Ω–µ—Ä, –æ–ø–∏—Å–∞–Ω–∏–µ, –≤–æ–∑—Ä–∞—Å—Ç)'}")
    logger.info(f"–ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: {BASE_DELAY} —Å–µ–∫")
    logger.info(f"–ò—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã: {EXCLUDE_COUNTRIES}")

    base_schedule_url = 'https://www.afisha.ru/prm/schedule_cinema/'

    try:
        # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è
        all_movies_data = parse_all_schedule_pages(base_schedule_url)

        if not all_movies_data:
            logger.error("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∏–ª—å–º–æ–≤ –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
            cal = Calendar()
            test_event = Event()
            test_event.name = "üé¨ –§–∏–ª—å–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            test_event.begin = datetime.now() + timedelta(days=1)
            test_event.end = test_event.begin + timedelta(hours=2)
            test_event.description = "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ñ–∏–ª—å–º—ã –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏ –∫–∏–Ω–æ—Ç–µ–∞—Ç—Ä–æ–≤"
            cal.events.add(test_event)
        else:
            cal = Calendar()
            successful_events = 0

            total_movies = len(all_movies_data)
            logger.info(f"üéØ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {total_movies} –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∏–ª—å–º–æ–≤ —Å –†–ê–°–®–ò–†–ï–ù–ù–´–ú–ò –¥–µ—Ç–∞–ª—è–º–∏")

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ñ–∏–ª—å–º–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            for idx, movie_data in enumerate(all_movies_data, 1):
                try:
                    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {idx}/{total_movies}: {movie_data['title']}")

                    # –ü–æ–ª—É—á–∞–µ–º –†–ê–°–®–ò–†–ï–ù–ù–£–Æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    if not SKIP_DETAILS and movie_data['url']:
                        logger.debug(f"–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π –¥–ª—è —Ñ–∏–ª—å–º–∞ {idx}")
                        countries, nearest_date, detailed_times, banner_url, description, age_rating = parse_movie_details_and_schedule(movie_data['url'])

                        movie_data['countries'] = countries
                        movie_data['nearest_show_date'] = nearest_date
                        if not movie_data['banner_url'] and banner_url:
                            movie_data['banner_url'] = banner_url
                        movie_data['description'] = description
                        movie_data['age_rating'] = age_rating

                        # –î–æ–ø–æ–ª–Ω—è–µ–º –≤—Ä–µ–º—è —Å–µ–∞–Ω—Å–æ–≤
                        if detailed_times:
                            all_times = list(set(movie_data['times'] + detailed_times))
                            movie_data['times'] = sorted(all_times)
                    else:
                        if SKIP_DETAILS:
                            logger.debug(f"–ü—Ä–æ–ø—É—Å–∫ –¥–µ—Ç–∞–ª–µ–π –¥–ª—è —Ñ–∏–ª—å–º–∞ {idx} (—Ñ–ª–∞–≥ --skip-details)")
                        movie_data['countries'] = []
                        movie_data['nearest_show_date'] = None
                        movie_data['description'] = None
                        movie_data['age_rating'] = None

                    # –°–æ–∑–¥–∞–µ–º –ö–†–ê–°–ò–í–û–ï —Å–æ–±—ã—Ç–∏–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è
                    event = create_calendar_event(movie_data)

                    if event:
                        cal.events.add(event)
                        successful_events += 1

                    # –ü—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 —Ñ–∏–ª—å–º–æ–≤
                    if idx % 10 == 0:
                        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {idx}/{total_movies} —Ñ–∏–ª—å–º–æ–≤, —Å–æ–∑–¥–∞–Ω–æ {successful_events} —Å–æ–±—ã—Ç–∏–π")

                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Ñ–∏–ª—å–º–∞–º–∏
                    if idx < total_movies:
                        smart_delay('default')

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∏–ª—å–º–∞ {movie_data['title']}: {e}")
                    continue

            logger.info(f"‚úÖ –ó–ê–í–ï–†–®–ï–ù–û: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_movies} —Ñ–∏–ª—å–º–æ–≤, —Å–æ–∑–¥–∞–Ω–æ {successful_events} –∫—Ä–∞—Å–∏–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        with open('calendar.ics', 'w', encoding='utf-8') as f:
            f.writelines(cal)

        logger.info(f"üìÖ –ö–∞–ª–µ–Ω–¥–∞—Ä—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω: calendar.ics ({len(cal.events)} —Å–æ–±—ã—Ç–∏–π)")
        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ: —Å–æ—Ö—Ä–∞–Ω—ë–Ω calendar.ics ({len(cal.events)} —Å–æ–±—ã—Ç–∏–π)")

        if os.path.exists('calendar.ics'):
            file_size = os.path.getsize('calendar.ics')
            logger.info(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")

    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        cal = Calendar()
        error_event = Event()
        error_event.name = "üé¨ –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"
        error_event.begin = datetime.now() + timedelta(days=1)
        error_event.end = error_event.begin + timedelta(hours=2)
        error_event.description = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {str(e)}"
        cal.events.add(error_event)

        with open('calendar.ics', 'w', encoding='utf-8') as f:
            f.writelines(cal)

        raise

if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        logger.info("–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise
